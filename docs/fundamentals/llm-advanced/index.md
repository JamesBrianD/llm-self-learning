# 第3节：LLM升级技术

## 🎯 学习目标

了解大语言模型的前沿优化技术，掌握MOE架构和分布式训练的基本概念。

**重点面试问题预览：**
- MOE是什么，有什么好处？
- 分布式训练的基本策略
- 大模型训练的工程挑战

## 📅 学习计划

**建议学习时间：2天**

- **Day 1**: MOE架构原理
- **Day 2**: 分布式训练概念

## 📚 学习路径

### 1. [MOE架构](moe.md)
- 专家混合模型原理
- 稀疏激活的优势
- 工程实现挑战

### 2. [分布式训练](distributed.md)
- 数据并行 vs 模型并行
- 流水线并行
- 通信优化策略

## ✅ 学习检验标准

完成以下两项才算掌握本节：

1. **问题解答**: 能解释MOE的工作原理和优势
2. **概念理解**: 理解大模型训练的分布式策略

## 🚀 开始学习

这一节是选修内容，重点了解概念即可。