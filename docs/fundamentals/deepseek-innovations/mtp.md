# MTPå¤štokené¢„æµ‹

## ğŸ¯ æœ¬èŠ‚ç›®æ ‡

æ·±å…¥ç†è§£Multi-Token Prediction (MTP)æŠ€æœ¯ï¼ŒæŒæ¡å…¶å¦‚ä½•é€šè¿‡å¹¶è¡Œé¢„æµ‹æå‡è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ã€‚

## ğŸ“ æŠ€æœ¯åŸç†è§£æ

### MTPè®¾è®¡èƒŒæ™¯

#### ä¼ ç»Ÿè®­ç»ƒçš„å±€é™æ€§

**å•tokené¢„æµ‹é—®é¢˜**:
```python
# ä¼ ç»Ÿnext-tokené¢„æµ‹
for position in sequence:
    prediction = model(input[:position])
    loss = cross_entropy(prediction, target[position])
    # æ¯æ­¥åªæœ‰ä¸€ä¸ªç›‘ç£ä¿¡å·
```

**é—®é¢˜åˆ†æ**:
1. **ä¿¡æ¯å¯†åº¦ä½**: æ¯ä¸ªå‰å‘ä¼ æ’­åªäº§ç”Ÿä¸€ä¸ªé¢„æµ‹
2. **é•¿æœŸä¾èµ–å¼±**: éš¾ä»¥å»ºç«‹è¿œè·ç¦»çš„ä¾èµ–å…³ç³»
3. **è®­ç»ƒæ•ˆç‡ä½**: åºåˆ—è¶Šé•¿ï¼Œæœ‰æ•ˆä¿¡å·è¶Šç¨€ç–

#### MTPè§£å†³æ–¹æ¡ˆ

**æ ¸å¿ƒæ€æƒ³**: åœ¨æ¯ä¸ªä½ç½®åŒæ—¶é¢„æµ‹æœªæ¥å¤šä¸ªtoken

```python
# MTPå¤štokené¢„æµ‹
for position in sequence:
    predictions = model.multi_head_predict(input[:position])
    # predictions[0] = é¢„æµ‹position+1çš„token
    # predictions[1] = é¢„æµ‹position+2çš„token  
    # predictions[n] = é¢„æµ‹position+n+1çš„token
    
    multi_loss = sum([
        cross_entropy(predictions[i], target[position+i+1])
        for i in range(n_predictions)
    ])
```

### MTPæ¶æ„è®¾è®¡

#### 1. å¤šé¢„æµ‹å¤´æ¶æ„

```python
class MultiTokenPredictionHead(nn.Module):
    """å¤štokené¢„æµ‹å¤´å®ç°"""
    
    def __init__(self, d_model, vocab_size, num_predictions, 
                 share_embeddings=True):
        super().__init__()
        self.d_model = d_model
        self.vocab_size = vocab_size
        self.num_predictions = num_predictions
        self.share_embeddings = share_embeddings
        
        # å…±äº«çš„Transformeréª¨å¹²ç½‘ç»œ
        self.backbone = TransformerBackbone(d_model)
        
        # å¤šä¸ªç‹¬ç«‹çš„é¢„æµ‹å¤´
        if share_embeddings:
            # å…±äº«è¾“å‡ºåµŒå…¥å±‚
            self.output_embedding = nn.Linear(d_model, vocab_size)
            self.prediction_heads = nn.ModuleList([
                PredictionHead(d_model, self.output_embedding)
                for _ in range(num_predictions)
            ])
        else:
            # ç‹¬ç«‹çš„é¢„æµ‹å¤´
            self.prediction_heads = nn.ModuleList([
                nn.Linear(d_model, vocab_size)
                for _ in range(num_predictions)
            ])
    
    def forward(self, x):
        # å…±äº«éª¨å¹²ç½‘ç»œæå–ç‰¹å¾
        hidden_states = self.backbone(x)
        
        # å¤šä¸ªé¢„æµ‹å¤´å¹¶è¡Œé¢„æµ‹
        predictions = []
        for i, head in enumerate(self.prediction_heads):
            if self.share_embeddings:
                # æ·»åŠ ä½ç½®ç‰¹å®šçš„è°ƒåˆ¶
                modulated_hidden = self.position_modulation(hidden_states, i)
                pred = head(modulated_hidden)
            else:
                pred = head(hidden_states)
            
            predictions.append(pred)
        
        return predictions
    
    def position_modulation(self, hidden, prediction_step):
        """ä½ç½®ç‰¹å®šçš„ç‰¹å¾è°ƒåˆ¶"""
        # ä¸ºä¸åŒé¢„æµ‹æ­¥éª¤æ·»åŠ ä½ç½®ç‰¹å®šçš„å˜æ¢
        step_embedding = self.step_embeddings[prediction_step]
        return hidden + step_embedding

class PredictionHead(nn.Module):
    """å•ä¸ªé¢„æµ‹å¤´"""
    
    def __init__(self, d_model, shared_output_layer=None):
        super().__init__()
        
        if shared_output_layer is not None:
            self.output_proj = shared_output_layer
        else:
            self.output_proj = nn.Linear(d_model, vocab_size)
        
        # é¢„æµ‹æ­¥éª¤ç‰¹å®šçš„å˜æ¢
        self.step_transform = nn.Sequential(
            nn.Linear(d_model, d_model),
            nn.GELU(),
            nn.Linear(d_model, d_model)
        )
    
    def forward(self, hidden_states):
        # æ­¥éª¤ç‰¹å®šå˜æ¢
        transformed = self.step_transform(hidden_states)
        
        # æ®‹å·®è¿æ¥
        output_hidden = hidden_states + transformed
        
        # è¾“å‡ºæŠ•å½±
        logits = self.output_proj(output_hidden)
        
        return logits
```

#### 2. æŸå¤±å‡½æ•°è®¾è®¡

```python
class MTPLoss(nn.Module):
    """å¤štokené¢„æµ‹æŸå¤±å‡½æ•°"""
    
    def __init__(self, num_predictions, loss_weights=None, 
                 auxiliary_loss_weight=0.1):
        super().__init__()
        self.num_predictions = num_predictions
        self.auxiliary_loss_weight = auxiliary_loss_weight
        
        if loss_weights is None:
            # é»˜è®¤æƒé‡ï¼šè·ç¦»è¶Šè¿œæƒé‡è¶Šå°
            self.loss_weights = [1.0 / (i + 1) for i in range(num_predictions)]
        else:
            self.loss_weights = loss_weights
    
    def forward(self, predictions, targets, primary_targets):
        """
        predictions: List[Tensor] - å¤šä¸ªé¢„æµ‹å¤´çš„è¾“å‡º
        targets: Tensor - å¯¹åº”çš„ç›®æ ‡åºåˆ—
        primary_targets: Tensor - ä¸»è¦ä»»åŠ¡ç›®æ ‡ï¼ˆnext-tokené¢„æµ‹ï¼‰
        """
        
        # ä¸»è¦æŸå¤±ï¼šä¼ ç»Ÿnext-tokené¢„æµ‹
        primary_loss = F.cross_entropy(predictions[0], primary_targets)
        
        # è¾…åŠ©æŸå¤±ï¼šå¤štokené¢„æµ‹
        auxiliary_losses = []
        for i, (pred, weight) in enumerate(zip(predictions, self.loss_weights)):
            if i < targets.size(1):
                target_slice = targets[:, i]
                aux_loss = F.cross_entropy(pred, target_slice)
                auxiliary_losses.append(weight * aux_loss)
        
        total_auxiliary_loss = sum(auxiliary_losses) / len(auxiliary_losses)
        
        # ç»„åˆæŸå¤±
        total_loss = primary_loss + self.auxiliary_loss_weight * total_auxiliary_loss
        
        return {
            'total_loss': total_loss,
            'primary_loss': primary_loss,
            'auxiliary_loss': total_auxiliary_loss
        }
```

#### 3. è®­ç»ƒç­–ç•¥

```python
class MTPTrainer:
    """MTPè®­ç»ƒå™¨"""
    
    def __init__(self, model, num_predictions=4, 
                 teacher_forcing=True):
        self.model = model
        self.num_predictions = num_predictions
        self.teacher_forcing = teacher_forcing
        self.loss_fn = MTPLoss(num_predictions)
    
    def train_step(self, batch):
        input_ids = batch['input_ids']
        batch_size, seq_len = input_ids.shape
        
        # ç”Ÿæˆå¤šä¸ªé¢„æµ‹ç›®æ ‡
        targets = self.prepare_multi_targets(input_ids)
        
        # å‰å‘ä¼ æ’­
        predictions = self.model(input_ids)
        
        # è®¡ç®—æŸå¤±
        loss_dict = self.loss_fn(
            predictions, 
            targets['multi_targets'],
            targets['primary_target']
        )
        
        return loss_dict
    
    def prepare_multi_targets(self, input_ids):
        """å‡†å¤‡å¤štokené¢„æµ‹çš„ç›®æ ‡"""
        batch_size, seq_len = input_ids.shape
        
        # ä¸»è¦ç›®æ ‡ï¼šä¸‹ä¸€ä¸ªtoken
        primary_target = input_ids[:, 1:]
        
        # å¤štokenç›®æ ‡ï¼šæœªæ¥nä¸ªtoken
        multi_targets = []
        for i in range(self.num_predictions):
            if i + 1 < seq_len:
                target = input_ids[:, i+1:]
                # å¡«å……åˆ°ç›¸åŒé•¿åº¦
                if target.size(1) < seq_len - 1:
                    padding = torch.zeros(
                        batch_size, 
                        seq_len - 1 - target.size(1),
                        dtype=input_ids.dtype,
                        device=input_ids.device
                    )
                    target = torch.cat([target, padding], dim=1)
                
                multi_targets.append(target)
        
        return {
            'primary_target': primary_target,
            'multi_targets': multi_targets
        }
```

### MTPçš„ä¼˜åŠ¿æœºåˆ¶

#### 1. å¯†é›†ç›‘ç£ä¿¡å·

**ä¼ ç»Ÿè®­ç»ƒ**:
```python
# æ¯ä¸ªä½ç½®åªæœ‰ä¸€ä¸ªç›‘ç£ä¿¡å·
supervision_density = 1 / sequence_length
```

**MTPè®­ç»ƒ**:
```python
# æ¯ä¸ªä½ç½®æœ‰å¤šä¸ªç›‘ç£ä¿¡å·
supervision_density = num_predictions / sequence_length
# é€šå¸¸æå‡2-4å€çš„ä¿¡å·å¯†åº¦
```

#### 2. é•¿æœŸä¾èµ–å»ºæ¨¡

```python
def analyze_dependency_modeling():
    """åˆ†æMTPå¦‚ä½•æ”¹å–„é•¿æœŸä¾èµ–å»ºæ¨¡"""
    
    # ä¼ ç»Ÿæ–¹å¼ï¼šåªèƒ½é€šè¿‡åå‘ä¼ æ’­å»ºç«‹ä¾èµ–
    traditional_dependency_range = max_gradient_flow_length
    
    # MTPæ–¹å¼ï¼šç›´æ¥å»ºç«‹è¿œè·ç¦»ç›‘ç£
    mtp_dependency_range = num_predictions * traditional_dependency_range
    
    print(f"ä¾èµ–å»ºæ¨¡èŒƒå›´æå‡: {mtp_dependency_range / traditional_dependency_range}Ã—")
```

#### 3. æ ·æœ¬æ•ˆç‡æå‡

```python
class SampleEfficiencyAnalyzer:
    """æ ·æœ¬æ•ˆç‡åˆ†æå™¨"""
    
    def __init__(self, sequence_length, num_predictions):
        self.seq_len = sequence_length
        self.num_pred = num_predictions
    
    def calculate_effective_samples(self, batch_size):
        """è®¡ç®—æœ‰æ•ˆæ ·æœ¬æ•°é‡"""
        
        # ä¼ ç»Ÿæ–¹å¼
        traditional_samples = batch_size * (self.seq_len - 1)
        
        # MTPæ–¹å¼
        mtp_samples = batch_size * (self.seq_len - 1) * self.num_pred
        
        efficiency_gain = mtp_samples / traditional_samples
        
        return {
            'traditional_samples': traditional_samples,
            'mtp_samples': mtp_samples,
            'efficiency_gain': efficiency_gain
        }
```

### æ¨ç†æ—¶çš„åº”ç”¨

#### 1. æŠ•æœºè§£ç åŠ é€Ÿ

```python
class SpeculativeDecoding:
    """åŸºäºMTPçš„æŠ•æœºè§£ç """
    
    def __init__(self, model_with_mtp, draft_model):
        self.main_model = model_with_mtp
        self.draft_model = draft_model
    
    def generate(self, input_ids, max_length):
        """æŠ•æœºè§£ç ç”Ÿæˆ"""
        current_ids = input_ids
        
        while current_ids.size(1) < max_length:
            # 1. ä½¿ç”¨draft modelå¿«é€Ÿç”Ÿæˆå€™é€‰
            draft_predictions = self.draft_model.multi_predict(
                current_ids, num_tokens=4
            )
            
            # 2. ä½¿ç”¨ä¸»æ¨¡å‹éªŒè¯å€™é€‰
            main_predictions = self.main_model.multi_predict(
                current_ids, num_tokens=4
            )
            
            # 3. æ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸åŒ¹é…çš„ä½ç½®
            accepted_length = self.find_acceptance_length(
                draft_predictions, main_predictions
            )
            
            # 4. æ¥å—éªŒè¯é€šè¿‡çš„token
            if accepted_length > 0:
                new_tokens = draft_predictions[:accepted_length]
                current_ids = torch.cat([current_ids, new_tokens], dim=1)
            else:
                # å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œä½¿ç”¨ä¸»æ¨¡å‹ç”Ÿæˆä¸€ä¸ªtoken
                next_token = self.main_model.generate_next(current_ids)
                current_ids = torch.cat([current_ids, next_token], dim=1)
        
        return current_ids
```

#### 2. å¹¶è¡Œè§£ç 

```python
def parallel_decoding_with_mtp(model, input_ids, beam_width=4):
    """åŸºäºMTPçš„å¹¶è¡Œè§£ç """
    
    batch_size, seq_len = input_ids.shape
    
    # 1. ä½¿ç”¨MTPåŒæ—¶é¢„æµ‹å¤šä¸ªä½ç½®
    multi_predictions = model.multi_predict(input_ids, num_tokens=beam_width)
    
    # 2. ä¸ºæ¯ä¸ªé¢„æµ‹ä½ç½®ç”Ÿæˆå€™é€‰
    candidates = []
    for i, predictions in enumerate(multi_predictions):
        top_k_tokens = torch.topk(predictions, k=beam_width, dim=-1)
        candidates.append(top_k_tokens.indices)
    
    # 3. æ„å»ºå€™é€‰åºåˆ—
    candidate_sequences = []
    for seq_candidate in itertools.product(*candidates):
        candidate_seq = torch.tensor(seq_candidate).unsqueeze(0)
        candidate_sequences.append(
            torch.cat([input_ids, candidate_seq], dim=1)
        )
    
    # 4. è¯„ä¼°æ‰€æœ‰å€™é€‰åºåˆ—
    scores = []
    for candidate in candidate_sequences:
        score = model.score_sequence(candidate)
        scores.append(score)
    
    # 5. é€‰æ‹©æœ€ä½³å€™é€‰
    best_idx = torch.argmax(torch.tensor(scores))
    return candidate_sequences[best_idx]
```

## ğŸ’¬ é¢è¯•é—®é¢˜è§£ç­”

### Q1: MTPå¦‚ä½•æå‡è®­ç»ƒæ•ˆç‡ï¼Ÿ

**æ ¸å¿ƒæœºåˆ¶**:

1. **ç›‘ç£ä¿¡å·å¯†åº¦**: ä»æ¯ä½ç½®1ä¸ªä¿¡å·æå‡åˆ°nä¸ªä¿¡å·
2. **æ ·æœ¬æ•ˆç‡**: ç›¸åŒæ•°æ®äº§ç”Ÿæ›´å¤šè®­ç»ƒä¿¡å·
3. **é•¿æœŸä¾èµ–**: ç›´æ¥å»ºç«‹è¿œè·ç¦»ç›‘ç£è¿æ¥
4. **å¹¶è¡Œè®­ç»ƒ**: å¤šä¸ªé¢„æµ‹å¤´å¯ä»¥å¹¶è¡Œè®¡ç®—

**å…·ä½“æ•°æ®**:
```
ä¼ ç»Ÿè®­ç»ƒï¼š1ä¸ªé¢„æµ‹/ä½ç½®
MTPè®­ç»ƒï¼š4ä¸ªé¢„æµ‹/ä½ç½® â†’ 4Ã—ä¿¡å·å¯†åº¦
```

### Q2: MTPåœ¨æ¨ç†æ—¶æœ‰ä»€ä¹ˆç”¨é€”ï¼Ÿ

**ä¸»è¦åº”ç”¨**:

1. **æŠ•æœºè§£ç **: ä¸€æ¬¡ç”Ÿæˆå¤šä¸ªå€™é€‰tokenï¼Œé€šè¿‡éªŒè¯åŠ é€Ÿ
2. **å¹¶è¡Œè§£ç **: åŒæ—¶è€ƒè™‘å¤šä¸ªæœªæ¥ä½ç½®çš„é¢„æµ‹
3. **è´¨é‡æå‡**: æ›´å¥½çš„é•¿æœŸè§„åˆ’èƒ½åŠ›
4. **beam searchä¼˜åŒ–**: æ›´å‡†ç¡®çš„å€™é€‰è¯„ä¼°

### Q3: MTPçš„è®­ç»ƒæˆæœ¬å¦‚ä½•ï¼Ÿ

**æˆæœ¬åˆ†æ**:

**å¢åŠ çš„æˆæœ¬**:
- å¤šä¸ªé¢„æµ‹å¤´çš„å‚æ•°ï¼ˆé€šå¸¸å¢åŠ 10-20%ï¼‰
- é¢å¤–çš„å‰å‘è®¡ç®—ï¼ˆå¢åŠ é¢„æµ‹å¤´éƒ¨åˆ†ï¼‰
- æ›´å¤æ‚çš„æŸå¤±è®¡ç®—

**æ”¶ç›Š**:
- æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦
- æ›´å¥½çš„æœ€ç»ˆæ€§èƒ½
- æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›

**æ€»ä½“è¯„ä¼°**: è™½ç„¶å•æ­¥æˆæœ¬å¢åŠ ï¼Œä½†æ”¶æ•›æ›´å¿«ï¼Œæ€»ä½“è®­ç»ƒæ•ˆç‡æå‡

## âœ… å­¦ä¹ æ£€éªŒ

- [ ] ç†è§£MTPç›¸æ¯”ä¼ ç»Ÿè®­ç»ƒçš„ä¼˜åŠ¿
- [ ] æŒæ¡å¤šé¢„æµ‹å¤´çš„æ¶æ„è®¾è®¡
- [ ] äº†è§£MTPåœ¨æ¨ç†åŠ é€Ÿä¸­çš„åº”ç”¨
- [ ] èƒ½åˆ†æMTPçš„æˆæœ¬æ•ˆç›Šæƒè¡¡

## ğŸ”— ç›¸å…³é“¾æ¥

- [ä¸Šä¸€èŠ‚ï¼šDeepSeek MoEåˆ›æ–°](deepseek-moe.md)
- [ç›¸å…³æŠ€æœ¯ï¼šæ€ç»´é“¾æŠ€æœ¯](../../applications/cot-evaluation/cot.md)
- [è¿”å›ï¼šDeepSeekä¼˜åŒ–æŠ€æœ¯æ¦‚è§ˆ](index.md)