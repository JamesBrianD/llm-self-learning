# 面试题库

## 🎯 目标

汇总LLM相关的高频面试问题，帮助快速复习和准备。

## 📚 按主题分类

### 模型基础
- Attention计算公式和原理
- Encoder-Only vs Decoder-Only架构
- MHA/MQA/GQA/MLA的区别
- KV Cache工作原理
- RoPE位置编码推导

### 模型应用  
- RAG的工作流程
- Agent的特点和能力
- CoT提升推理的原理
- 上下文工程的核心技巧

### 工程实践
- 模型部署优化
- 推理加速技术
- 分布式训练策略
- 模型评测方法

## 🔥 高频问题 Top 10

1. **Attention机制的数学公式是什么？**
2. **为什么要除以√d_k？**
3. **GPT和BERT的架构区别？**
4. **KV Cache如何加速推理？**
5. **什么是RoPE？如何推导？**
6. **MQA相比MHA的优势？**
7. **Pre-Norm vs Post-Norm？**
8. **RAG的工作流程？**
9. **Agent和普通LLM的区别？**
10. **如何设计有效的提示词？**

## 💡 答题技巧

1. **先说核心，再展开细节**
2. **结合数学公式和代码实现**
3. **提及实际应用和工程考虑**
4. **对比不同方案的优劣**

每个问题都在对应章节有详细解答，建议结合学习！