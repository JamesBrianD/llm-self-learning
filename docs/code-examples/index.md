# 代码实现

## 🎯 目标

提供LLM相关技术的可执行代码示例，帮助加深理解。

## 💻 代码分类

### 基础实现
- [Self-Attention机制](https://www.deep-ml.com/problems/53)
- [Multi-Head Attention](https://www.deep-ml.com/problems/94)
- [Softmax函数](https://www.deep-ml.com/problems/23)

### 优化技术
- GQA (Grouped-Query Attention) 实现
- KV Cache演示代码
- RoPE位置编码完整实现
- 三种归一化技术对比

### 应用示例
- RAG系统简化版
- 简单Agent框架
- 提示词工程模板

## 🛠️ 实践建议

1. **动手编写**: 不要只看代码，要自己实现
2. **理解原理**: 每行代码都要知道为什么这样写
3. **调试运行**: 确保代码能正确执行
4. **性能对比**: 测试不同实现的效果差异

## 📋 检验清单

- [ ] 完成Self-Attention编程练习
- [ ] 实现KV Cache演示
- [ ] 编写RoPE位置编码
- [ ] 对比不同归一化技术
- [ ] 设计提示词模板

所有代码都在对应技术章节中提供，这里作为总入口！