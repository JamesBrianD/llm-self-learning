
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="大语言模型与AI学习资源汇总">
      
      
      
        <link rel="canonical" href="https://jamesbriand.github.io/llm-self-learning/fundamentals/attention-advanced/mha-variants/">
      
      
        <link rel="prev" href="../">
      
      
        <link rel="next" href="../kv-cache/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.16">
    
    
      
        <title>多头注意力变体 - LLM 自学指南</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.7e37652d.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto Slab";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="light-blue" data-md-color-accent="deep-purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="LLM 自学指南" class="md-header__button md-logo" aria-label="LLM 自学指南" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            LLM 自学指南
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              多头注意力变体
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="light-blue" data-md-color-accent="deep-purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="cyan" data-md-color-accent="deep-purple"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="LLM 自学指南" class="md-nav__button md-logo" aria-label="LLM 自学指南" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    LLM 自学指南
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    首页
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting-started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    学习指南
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    模型基础
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            模型基础
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    第1节 Transformer基础
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            第1节 Transformer基础
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    学习概览
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/attention/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Attention机制
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/ffn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    前馈神经网络
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/encoder-decoder/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    编码器-解码器架构
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/language-models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    语言模型架构
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/tokenizer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tokenizer技术
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" checked>
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    第2节 Attention升级
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            第2节 Attention升级
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    学习概览
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    多头注意力变体
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    多头注意力变体
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      🎯 本节目标
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      📖 阅读材料
    </span>
  </a>
  
    <nav class="md-nav" aria-label="📖 阅读材料">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      核心技术文章
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      📝 知识总结
    </span>
  </a>
  
    <nav class="md-nav" aria-label="📝 知识总结">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      技术演进路径
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      各变体详细对比
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      核心技术细节
    </span>
  </a>
  
    <nav class="md-nav" aria-label="核心技术细节">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-mha-multi-head-attention" class="md-nav__link">
    <span class="md-ellipsis">
      1. MHA (Multi-Head Attention)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-mqa-multi-query-attention" class="md-nav__link">
    <span class="md-ellipsis">
      2. MQA (Multi-Query Attention)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-gqa-grouped-query-attention" class="md-nav__link">
    <span class="md-ellipsis">
      3. GQA (Grouped-Query Attention)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      💬 面试问题解答
    </span>
  </a>
  
    <nav class="md-nav" aria-label="💬 面试问题解答">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#q1-mhamqagqamla" class="md-nav__link">
    <span class="md-ellipsis">
      Q1: MHA、MQA、GQA、MLA都是什么？
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mla" class="md-nav__link">
    <span class="md-ellipsis">
      🔬 MLA技术深度解析
    </span>
  </a>
  
    <nav class="md-nav" aria-label="🔬 MLA技术深度解析">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mla_1" class="md-nav__link">
    <span class="md-ellipsis">
      MLA核心创新
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MLA核心创新">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-kv" class="md-nav__link">
    <span class="md-ellipsis">
      1. 低秩KV联合压缩
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-rope" class="md-nav__link">
    <span class="md-ellipsis">
      2. RoPE解耦机制
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      3. 权重吸收优化
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      内存效率对比
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    <span class="md-ellipsis">
      性能保持机制
    </span>
  </a>
  
    <nav class="md-nav" aria-label="性能保持机制">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      1. 表达能力保持
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2. 训练稳定性
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_1" class="md-nav__link">
    <span class="md-ellipsis">
      3. 位置敏感性
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#q2" class="md-nav__link">
    <span class="md-ellipsis">
      Q2: 为什么需要这些优化？
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#q3" class="md-nav__link">
    <span class="md-ellipsis">
      Q3: 各变体的优缺点对比？
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#q4" class="md-nav__link">
    <span class="md-ellipsis">
      Q4: 如何选择合适的注意力机制？
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    <span class="md-ellipsis">
      💻 代码实现
    </span>
  </a>
  
    <nav class="md-nav" aria-label="💻 代码实现">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-softmax" class="md-nav__link">
    <span class="md-ellipsis">
      练习1: 实现Softmax函数
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-mhagqa" class="md-nav__link">
    <span class="md-ellipsis">
      练习2: MHA到GQA的适配
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-kv-cache" class="md-nav__link">
    <span class="md-ellipsis">
      练习3: KV Cache实现预览
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    <span class="md-ellipsis">
      ✅ 学习检验
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    <span class="md-ellipsis">
      🔗 相关链接
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../kv-cache/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    KV Cache技术
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../normalization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    归一化技术
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../positional-encoding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    位置编码
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
        
          
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    第3节 LLM升级技术
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            第3节 LLM升级技术
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../llm-advanced/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    学习概览
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../llm-advanced/moe/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MOE架构
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../llm-advanced/distributed/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    分布式训练
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    第4节 DeepSeek优化技术
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            第4节 DeepSeek优化技术
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deepseek-innovations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    学习概览
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deepseek-innovations/mla/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MLA核心技术
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deepseek-innovations/deepseek-moe/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DeepSeek MoE创新
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../deepseek-innovations/mtp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MTP多token预测
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    模型训练
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            模型训练
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    第8节 参数高效微调
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            第8节 参数高效微调
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/parameter-efficient/lora/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LoRA技术
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    第9节 后训练技术
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            第9节 后训练技术
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/post-training/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    学习概览
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/post-training/post-pretraining/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    后预训练技术
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/post-training/supervised-finetuning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    监督微调方法
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_3" >
        
          
          <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    第10节 强化学习与对齐
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_3">
            <span class="md-nav__icon md-icon"></span>
            第10节 强化学习与对齐
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/rlhf-alignment/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    学习概览
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/rlhf-alignment/rlhf-core/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RLHF核心技术
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/rlhf-alignment/dpo-constitutional/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DPO与Constitutional AI
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/rlhf-alignment/reward-modeling/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    奖励模型训练
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/rlhf-alignment/frameworks-implementation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    框架与实现
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    大模型应用
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            大模型应用
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1" >
        
          
          <label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    第5节 Context Engineering
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1">
            <span class="md-nav__icon md-icon"></span>
            第5节 Context Engineering
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../applications/context-engineering/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    学习概览
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../applications/context-engineering/practices/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    上下文工程实践
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
        
          
          <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    第6节 RAG与Agent
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            第6节 RAG与Agent
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../applications/rag-agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    学习概览
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../applications/rag-agent/rag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RAG技术
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../applications/rag-agent/agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AI Agent
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    第7节 CoT与评测
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            第7节 CoT与评测
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../applications/cot-evaluation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    学习概览
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../applications/cot-evaluation/cot/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    思维链技术
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../applications/cot-evaluation/langchain/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LangChain框架
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../applications/cot-evaluation/evaluation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    模型评测
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../interview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    面试题库
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../code-examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    代码实现
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      🎯 本节目标
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      📖 阅读材料
    </span>
  </a>
  
    <nav class="md-nav" aria-label="📖 阅读材料">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      核心技术文章
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      📝 知识总结
    </span>
  </a>
  
    <nav class="md-nav" aria-label="📝 知识总结">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      技术演进路径
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      各变体详细对比
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      核心技术细节
    </span>
  </a>
  
    <nav class="md-nav" aria-label="核心技术细节">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-mha-multi-head-attention" class="md-nav__link">
    <span class="md-ellipsis">
      1. MHA (Multi-Head Attention)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-mqa-multi-query-attention" class="md-nav__link">
    <span class="md-ellipsis">
      2. MQA (Multi-Query Attention)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-gqa-grouped-query-attention" class="md-nav__link">
    <span class="md-ellipsis">
      3. GQA (Grouped-Query Attention)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      💬 面试问题解答
    </span>
  </a>
  
    <nav class="md-nav" aria-label="💬 面试问题解答">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#q1-mhamqagqamla" class="md-nav__link">
    <span class="md-ellipsis">
      Q1: MHA、MQA、GQA、MLA都是什么？
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mla" class="md-nav__link">
    <span class="md-ellipsis">
      🔬 MLA技术深度解析
    </span>
  </a>
  
    <nav class="md-nav" aria-label="🔬 MLA技术深度解析">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mla_1" class="md-nav__link">
    <span class="md-ellipsis">
      MLA核心创新
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MLA核心创新">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-kv" class="md-nav__link">
    <span class="md-ellipsis">
      1. 低秩KV联合压缩
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-rope" class="md-nav__link">
    <span class="md-ellipsis">
      2. RoPE解耦机制
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      3. 权重吸收优化
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      内存效率对比
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    <span class="md-ellipsis">
      性能保持机制
    </span>
  </a>
  
    <nav class="md-nav" aria-label="性能保持机制">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      1. 表达能力保持
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2. 训练稳定性
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_1" class="md-nav__link">
    <span class="md-ellipsis">
      3. 位置敏感性
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#q2" class="md-nav__link">
    <span class="md-ellipsis">
      Q2: 为什么需要这些优化？
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#q3" class="md-nav__link">
    <span class="md-ellipsis">
      Q3: 各变体的优缺点对比？
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#q4" class="md-nav__link">
    <span class="md-ellipsis">
      Q4: 如何选择合适的注意力机制？
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    <span class="md-ellipsis">
      💻 代码实现
    </span>
  </a>
  
    <nav class="md-nav" aria-label="💻 代码实现">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-softmax" class="md-nav__link">
    <span class="md-ellipsis">
      练习1: 实现Softmax函数
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-mhagqa" class="md-nav__link">
    <span class="md-ellipsis">
      练习2: MHA到GQA的适配
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-kv-cache" class="md-nav__link">
    <span class="md-ellipsis">
      练习3: KV Cache实现预览
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    <span class="md-ellipsis">
      ✅ 学习检验
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    <span class="md-ellipsis">
      🔗 相关链接
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="_1">多头注意力变体<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<h2 id="_2">🎯 本节目标<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<p>理解从MHA到MLA的技术演进，掌握不同注意力机制的优化原理和应用场景。</p>
<h2 id="_3">📖 阅读材料<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<h3 id="_4">核心技术文章<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h3>
<ol>
<li><a href="https://lengm.cn/post/20250226_attention/">Transformer的Attention及其各种变体</a> - 详细对比分析</li>
<li><a href="https://spaces.ac.cn/archives/10091">缓存与效果的极限拉扯：从MHA、MQA、GQA到MLA</a> - 科学空间深度解析</li>
</ol>
<h2 id="_5">📝 知识总结<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h2>
<h3 id="_6">技术演进路径<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>MHA (标准多头) → MQA (共享KV) → GQA (分组共享) → MLA (潜在空间)
</code></pre></div>
<h3 id="_7">各变体详细对比<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>变体</th>
<th>KV Cache需求</th>
<th>计算复杂度</th>
<th>性能表现</th>
<th>主要应用</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>MHA</strong></td>
<td>O(h×d×L)</td>
<td>O(H x N^2 x D)</td>
<td>基准性能</td>
<td>标准Transformer</td>
</tr>
<tr>
<td><strong>MQA</strong></td>
<td>O(d×L)</td>
<td>O(N^2×D)</td>
<td>轻微下降</td>
<td>资源受限场景</td>
</tr>
<tr>
<td><strong>GQA</strong></td>
<td>O(g×d×L)</td>
<td>O(G×N^2×D)</td>
<td>平衡优秀</td>
<td>主流大模型</td>
</tr>
<tr>
<td><strong>MLA</strong></td>
<td>最优化</td>
<td>O(R×N^2×D)</td>
<td>接近MHA</td>
<td>长上下文</td>
</tr>
</tbody>
</table>
<blockquote>
<p>其中：h=头数，d=维度，L=序列长度，g=组数</p>
</blockquote>
<h3 id="_8">核心技术细节<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h3>
<h4 id="1-mha-multi-head-attention">1. MHA (Multi-Head Attention)<a class="headerlink" href="#1-mha-multi-head-attention" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="c1"># 每个头都有独立的Q、K、V</span>
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_heads</span><span class="p">):</span>
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>    <span class="n">Q_i</span> <span class="o">=</span> <span class="nb">input</span> <span class="o">@</span> <span class="n">W_Q_i</span>  <span class="c1"># 每个头独立的查询矩阵</span>
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>    <span class="n">K_i</span> <span class="o">=</span> <span class="nb">input</span> <span class="o">@</span> <span class="n">W_K_i</span>  <span class="c1"># 每个头独立的键矩阵  </span>
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>    <span class="n">V_i</span> <span class="o">=</span> <span class="nb">input</span> <span class="o">@</span> <span class="n">W_V_i</span>  <span class="c1"># 每个头独立的值矩阵</span>
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>    <span class="n">head_i</span> <span class="o">=</span> <span class="n">attention</span><span class="p">(</span><span class="n">Q_i</span><span class="p">,</span> <span class="n">K_i</span><span class="p">,</span> <span class="n">V_i</span><span class="p">)</span>
</code></pre></div>
<h4 id="2-mqa-multi-query-attention">2. MQA (Multi-Query Attention)<a class="headerlink" href="#2-mqa-multi-query-attention" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="c1"># 所有头共享K、V，只有Q独立</span>
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="n">K_shared</span> <span class="o">=</span> <span class="nb">input</span> <span class="o">@</span> <span class="n">W_K</span>  <span class="c1"># 共享的键矩阵</span>
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="n">V_shared</span> <span class="o">=</span> <span class="nb">input</span> <span class="o">@</span> <span class="n">W_V</span>  <span class="c1"># 共享的值矩阵</span>
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_heads</span><span class="p">):</span>
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>    <span class="n">Q_i</span> <span class="o">=</span> <span class="nb">input</span> <span class="o">@</span> <span class="n">W_Q_i</span>  <span class="c1"># 每个头独立的查询矩阵</span>
<a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>    <span class="n">head_i</span> <span class="o">=</span> <span class="n">attention</span><span class="p">(</span><span class="n">Q_i</span><span class="p">,</span> <span class="n">K_shared</span><span class="p">,</span> <span class="n">V_shared</span><span class="p">)</span>
</code></pre></div>
<h4 id="3-gqa-grouped-query-attention">3. GQA (Grouped-Query Attention)<a class="headerlink" href="#3-gqa-grouped-query-attention" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="c1"># 分组共享：每组内共享K、V</span>
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="n">num_groups</span> <span class="o">=</span> <span class="n">num_heads</span> <span class="o">//</span> <span class="n">group_size</span>
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_groups</span><span class="p">):</span>
<a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>    <span class="n">K_g</span> <span class="o">=</span> <span class="nb">input</span> <span class="o">@</span> <span class="n">W_K_g</span>  <span class="c1"># 组共享的键矩阵</span>
<a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>    <span class="n">V_g</span> <span class="o">=</span> <span class="nb">input</span> <span class="o">@</span> <span class="n">W_V_g</span>  <span class="c1"># 组共享的值矩阵</span>
<a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>
<a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">group_size</span><span class="p">):</span>
<a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>        <span class="n">Q_i</span> <span class="o">=</span> <span class="nb">input</span> <span class="o">@</span> <span class="n">W_Q_i</span>
<a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>        <span class="n">head_i</span> <span class="o">=</span> <span class="n">attention</span><span class="p">(</span><span class="n">Q_i</span><span class="p">,</span> <span class="n">K_g</span><span class="p">,</span> <span class="n">V_g</span><span class="p">)</span>
</code></pre></div>
<h2 id="_9">💬 面试问题解答<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h2>
<h3 id="q1-mhamqagqamla">Q1: MHA、MQA、GQA、MLA都是什么？<a class="headerlink" href="#q1-mhamqagqamla" title="Permanent link">&para;</a></h3>
<p><strong>简洁回答：</strong>
这是Transformer注意力机制的四个演进阶段，主要优化KV Cache的存储需求：</p>
<ul>
<li><strong>MHA</strong>: 标准多头注意力，每个头独立QKV</li>
<li><strong>MQA</strong>: 多查询注意力，所有头共享KV</li>
<li><strong>GQA</strong>: 分组查询注意力，分组内共享KV  </li>
<li><strong>MLA</strong>: 多头潜在注意力，通过低秩分解优化</li>
</ul>
<p><strong>技术细节：</strong></p>
<p><strong>MHA问题</strong>: KV Cache随头数线性增长，内存开销大
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>内存需求 = 头数 × 维度 × 序列长度
</code></pre></div></p>
<p><strong>MQA解决方案</strong>: 共享KV矩阵，内存需求降低h倍
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="c1"># 从 h×(d_k + d_v) 降低到 (d_k + d_v)</span>
</code></pre></div></p>
<p><strong>GQA平衡方案</strong>: 分组共享，兼顾性能和效率
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="c1"># 内存需求 = 组数 × 维度 × 序列长度  </span>
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="c1"># 其中：组数 = 头数 / 每组头数</span>
</code></pre></div></p>
<p><strong>MLA终极优化</strong>: 潜在空间投影，最小化KV Cache</p>
<h2 id="mla">🔬 MLA技术深度解析<a class="headerlink" href="#mla" title="Permanent link">&para;</a></h2>
<h3 id="mla_1">MLA核心创新<a class="headerlink" href="#mla_1" title="Permanent link">&para;</a></h3>
<p><strong>Multi-head Latent Attention (MLA)</strong> 是DeepSeek团队提出的革命性注意力机制，通过三大创新显著降低KV Cache内存需求：</p>
<h4 id="1-kv">1. 低秩KV联合压缩<a class="headerlink" href="#1-kv" title="Permanent link">&para;</a></h4>
<p><strong>核心思想</strong>: 将高维的Key和Value矩阵联合压缩到低维潜在空间</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="c1"># 传统方式：每个头独立存储KV</span>
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="n">traditional_kv_cache</span> <span class="o">=</span> <span class="n">num_heads</span> <span class="err">×</span> <span class="n">head_dim</span> <span class="err">×</span> <span class="n">seq_len</span> <span class="err">×</span> <span class="mi">2</span>  <span class="c1"># K和V</span>
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="c1"># MLA方式：压缩后的潜在向量</span>
<a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a><span class="n">mla_kv_cache</span> <span class="o">=</span> <span class="n">compressed_dim</span> <span class="err">×</span> <span class="n">seq_len</span> <span class="o">+</span> <span class="n">rope_dim</span> <span class="err">×</span> <span class="n">seq_len</span>
</code></pre></div>
<p><strong>压缩过程</strong>:
<span class="arithmatex">\(<span class="arithmatex">\(c_t^{KV} = x_t W^{DKV}\)</span>\)</span></p>
<p>其中 <span class="arithmatex">\(W^{DKV} \in \mathbb{R}^{d \times d_c}\)</span>，<span class="arithmatex">\(d_c \ll h \cdot d_h\)</span></p>
<h4 id="2-rope">2. RoPE解耦机制<a class="headerlink" href="#2-rope" title="Permanent link">&para;</a></h4>
<p><strong>问题</strong>: 位置编码与压缩机制的冲突
- 传统RoPE需要在原始QK空间中应用
- 压缩破坏了位置信息的正确传递</p>
<p><strong>解决方案</strong>: 将Query和Key分为两部分
- <strong>语义部分</strong> (<span class="arithmatex">\(q^C, k^C\)</span>): 携带主要语义信息，可以压缩
- <strong>位置部分</strong> (<span class="arithmatex">\(q^R, k^R\)</span>): 携带位置信息，保持原维度</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">mla_with_rope_decoupling</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">position</span><span class="p">):</span>
<a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>    <span class="c1"># 1. 生成潜在向量</span>
<a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>    <span class="n">c_kv</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">W_down_kv</span>  <span class="c1"># 压缩</span>
<a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>
<a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>    <span class="c1"># 2. Query分离</span>
<a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>    <span class="n">q</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">W_q</span>
<a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>    <span class="n">q_c</span><span class="p">,</span> <span class="n">q_r</span> <span class="o">=</span> <span class="n">q</span><span class="p">[:,</span> <span class="p">:</span><span class="n">d_c</span><span class="p">],</span> <span class="n">q</span><span class="p">[:,</span> <span class="n">d_c</span><span class="p">:]</span>  <span class="c1"># 语义 + 位置</span>
<a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>
<a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>    <span class="c1"># 3. Key分离和恢复</span>
<a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>    <span class="n">k_c</span> <span class="o">=</span> <span class="n">c_kv</span> <span class="o">@</span> <span class="n">W_up_k</span>   <span class="c1"># 从潜在空间恢复语义Key</span>
<a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a>    <span class="n">k_r</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">W_k_r</span>       <span class="c1"># 直接生成位置Key</span>
<a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a>
<a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a>    <span class="c1"># 4. 分别应用RoPE</span>
<a id="__codelineno-8-14" name="__codelineno-8-14" href="#__codelineno-8-14"></a>    <span class="n">q_r</span> <span class="o">=</span> <span class="n">apply_rope</span><span class="p">(</span><span class="n">q_r</span><span class="p">,</span> <span class="n">position</span><span class="p">)</span>
<a id="__codelineno-8-15" name="__codelineno-8-15" href="#__codelineno-8-15"></a>    <span class="n">k_r</span> <span class="o">=</span> <span class="n">apply_rope</span><span class="p">(</span><span class="n">k_r</span><span class="p">,</span> <span class="n">position</span><span class="p">)</span>
<a id="__codelineno-8-16" name="__codelineno-8-16" href="#__codelineno-8-16"></a>
<a id="__codelineno-8-17" name="__codelineno-8-17" href="#__codelineno-8-17"></a>    <span class="c1"># 5. 组合计算</span>
<a id="__codelineno-8-18" name="__codelineno-8-18" href="#__codelineno-8-18"></a>    <span class="n">q_combined</span> <span class="o">=</span> <span class="n">concat</span><span class="p">([</span><span class="n">q_c</span><span class="p">,</span> <span class="n">q_r</span><span class="p">])</span>
<a id="__codelineno-8-19" name="__codelineno-8-19" href="#__codelineno-8-19"></a>    <span class="n">k_combined</span> <span class="o">=</span> <span class="n">concat</span><span class="p">([</span><span class="n">k_c</span><span class="p">,</span> <span class="n">k_r</span><span class="p">])</span>
<a id="__codelineno-8-20" name="__codelineno-8-20" href="#__codelineno-8-20"></a>    <span class="n">v</span> <span class="o">=</span> <span class="n">c_kv</span> <span class="o">@</span> <span class="n">W_up_v</span>
<a id="__codelineno-8-21" name="__codelineno-8-21" href="#__codelineno-8-21"></a>
<a id="__codelineno-8-22" name="__codelineno-8-22" href="#__codelineno-8-22"></a>    <span class="k">return</span> <span class="n">attention</span><span class="p">(</span><span class="n">q_combined</span><span class="p">,</span> <span class="n">k_combined</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
</code></pre></div>
<h4 id="3">3. 权重吸收优化<a class="headerlink" href="#3" title="Permanent link">&para;</a></h4>
<p><strong>目标</strong>: 减少推理时的矩阵乘法操作</p>
<p><strong>技术</strong>: 利用矩阵乘法结合律，预先合并权重矩阵</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="c1"># 原始计算：两次矩阵乘法</span>
<a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="n">c_kv</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">W_down_kv</span>
<a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a><span class="n">k</span> <span class="o">=</span> <span class="n">c_kv</span> <span class="o">@</span> <span class="n">W_up_k</span>
<a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a>
<a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a><span class="c1"># 权重吸收：合并为一次乘法</span>
<a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a><span class="n">W_combined</span> <span class="o">=</span> <span class="n">W_down_kv</span> <span class="o">@</span> <span class="n">W_up_k</span>
<a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a><span class="n">k</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">W_combined</span>
</code></pre></div>
<h3 id="_10">内存效率对比<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>方法</th>
<th>KV Cache大小</th>
<th>压缩比</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>MHA</strong></td>
<td><span class="arithmatex">\(2 h \cdot d_h \cdot L\)</span></td>
<td>1.0× (基准)</td>
</tr>
<tr>
<td><strong>MQA</strong></td>
<td><span class="arithmatex">\(2 d_h \cdot L\)</span></td>
<td><span class="arithmatex">\(h\)</span>×</td>
</tr>
<tr>
<td><strong>GQA</strong></td>
<td><span class="arithmatex">\(2 g \cdot d_h \cdot L\)</span></td>
<td><span class="arithmatex">\(h/g\)</span>×</td>
</tr>
<tr>
<td><strong>MLA</strong></td>
<td><span class="arithmatex">\((d_c + d_h^R) \cdot L\)</span></td>
<td>~10-20×</td>
</tr>
</tbody>
</table>
<p><strong>具体例子</strong> (LLaMA-7B规模):
- 原始MHA: 32头 × 128维 × 2 = 8192维/token
- MLA压缩: 512维 + 128维 = 640维/token
- <strong>压缩比</strong>: 12.8×</p>
<h3 id="_11">性能保持机制<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h3>
<p>尽管大幅压缩，MLA通过巧妙设计保持了接近MHA的性能：</p>
<h4 id="1">1. 表达能力保持<a class="headerlink" href="#1" title="Permanent link">&para;</a></h4>
<ul>
<li>低秩假设：大部分注意力模式可以用低秩矩阵近似</li>
<li>关键信息保留：位置信息通过解耦机制完整保留</li>
<li>渐进恢复：多层堆叠逐步恢复完整信息</li>
</ul>
<h4 id="2">2. 训练稳定性<a class="headerlink" href="#2" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="c1"># 残差连接确保训练稳定</span>
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a><span class="k">def</span><span class="w"> </span><span class="nf">mla_block</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>    <span class="c1"># MLA注意力</span>
<a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>    <span class="n">attn_out</span> <span class="o">=</span> <span class="n">mla_attention</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">attn_out</span>  <span class="c1"># 残差连接</span>
<a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a>
<a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a>    <span class="c1"># FFN</span>
<a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a>    <span class="n">ffn_out</span> <span class="o">=</span> <span class="n">feed_forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-10-9" name="__codelineno-10-9" href="#__codelineno-10-9"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">ffn_out</span>   <span class="c1"># 残差连接</span>
<a id="__codelineno-10-10" name="__codelineno-10-10" href="#__codelineno-10-10"></a>
<a id="__codelineno-10-11" name="__codelineno-10-11" href="#__codelineno-10-11"></a>    <span class="k">return</span> <span class="n">x</span>
</code></pre></div>
<h4 id="3_1">3. 位置敏感性<a class="headerlink" href="#3_1" title="Permanent link">&para;</a></h4>
<ul>
<li>RoPE解耦确保位置信息不丢失</li>
<li>位置编码维度可以根据任务需求调整</li>
<li>长序列外推能力得到保持</li>
</ul>
<h3 id="q2">Q2: 为什么需要这些优化？<a class="headerlink" href="#q2" title="Permanent link">&para;</a></h3>
<p><strong>核心动机：</strong></p>
<ol>
<li><strong>内存瓶颈</strong></li>
<li>长序列推理时KV Cache占用大量显存</li>
<li>
<p>限制了模型的部署和扩展能力</p>
</li>
<li>
<p><strong>推理速度</strong></p>
</li>
<li>减少内存访问，提高计算效率</li>
<li>
<p>支持更大的batch size</p>
</li>
<li>
<p><strong>成本考虑</strong></p>
</li>
<li>降低硬件要求</li>
<li>提高服务并发能力</li>
</ol>
<h3 id="q3">Q3: 各变体的优缺点对比？<a class="headerlink" href="#q3" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>维度</th>
<th>MHA</th>
<th>MQA</th>
<th>GQA</th>
<th>MLA</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>性能</strong></td>
<td>🟢 基准最好</td>
<td>🟡 轻微下降</td>
<td>🟢 接近MHA</td>
<td>🟢 超越MHA</td>
</tr>
<tr>
<td><strong>内存</strong></td>
<td>🔴 需求最高</td>
<td>🟢 显著降低</td>
<td>🟡 适中</td>
<td>🟢 最优</td>
</tr>
<tr>
<td><strong>速度</strong></td>
<td>🟡 标准</td>
<td>🟢 最快</td>
<td>🟢 较快</td>
<td>🟢 优秀</td>
</tr>
<tr>
<td><strong>实现</strong></td>
<td>🟢 简单</td>
<td>🟢 简单</td>
<td>🟡 中等</td>
<td>🔴 复杂</td>
</tr>
</tbody>
</table>
<h3 id="q4">Q4: 如何选择合适的注意力机制？<a class="headerlink" href="#q4" title="Permanent link">&para;</a></h3>
<p><strong>选择策略：</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="k">if</span> <span class="n">资源充足</span> <span class="ow">and</span> <span class="n">追求最佳性能</span><span class="p">:</span>
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>    <span class="n">选择</span> <span class="n">MHA</span>
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a><span class="k">elif</span> <span class="n">资源严重受限</span> <span class="ow">and</span> <span class="n">可接受性能损失</span><span class="p">:</span>
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>    <span class="n">选择</span> <span class="n">MQA</span>  
<a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a><span class="k">elif</span> <span class="n">需要平衡性能和效率</span><span class="p">:</span>
<a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>    <span class="n">选择</span> <span class="n">GQA</span>  <span class="c1"># 主流选择</span>
<a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a><span class="k">elif</span> <span class="n">长上下文</span> <span class="ow">and</span> <span class="n">内存敏感</span><span class="p">:</span>
<a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a>    <span class="n">选择</span> <span class="n">MLA</span>
</code></pre></div>
<p><strong>实际考虑因素：</strong>
- 硬件内存限制
- 序列长度需求<br />
- 延迟要求
- 开发复杂度</p>
<h2 id="_12">💻 代码实现<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h2>
<h3 id="1-softmax">练习1: 实现Softmax函数<a class="headerlink" href="#1-softmax" title="Permanent link">&para;</a></h3>
<p><strong>平台</strong>: <a href="https://www.deep-ml.com/problems/23">Deep-ML Softmax</a></p>
<h3 id="2-mhagqa">练习2: MHA到GQA的适配<a class="headerlink" href="#2-mhagqa" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="k">class</span><span class="w"> </span><span class="nc">GroupedQueryAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">num_groups</span><span class="p">):</span>
<a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a>        <span class="k">assert</span> <span class="n">num_heads</span> <span class="o">%</span> <span class="n">num_groups</span> <span class="o">==</span> <span class="mi">0</span>
<a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>
<a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
<a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
<a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_groups</span> <span class="o">=</span> <span class="n">num_groups</span>
<a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">heads_per_group</span> <span class="o">=</span> <span class="n">num_heads</span> <span class="o">//</span> <span class="n">num_groups</span>
<a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">//</span> <span class="n">num_heads</span>
<a id="__codelineno-12-11" name="__codelineno-12-11" href="#__codelineno-12-11"></a>
<a id="__codelineno-12-12" name="__codelineno-12-12" href="#__codelineno-12-12"></a>        <span class="c1"># Q矩阵：每个头独立</span>
<a id="__codelineno-12-13" name="__codelineno-12-13" href="#__codelineno-12-13"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
<a id="__codelineno-12-14" name="__codelineno-12-14" href="#__codelineno-12-14"></a>
<a id="__codelineno-12-15" name="__codelineno-12-15" href="#__codelineno-12-15"></a>        <span class="c1"># K,V矩阵：按组共享</span>
<a id="__codelineno-12-16" name="__codelineno-12-16" href="#__codelineno-12-16"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_k</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_groups</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>
<a id="__codelineno-12-17" name="__codelineno-12-17" href="#__codelineno-12-17"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_groups</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>
<a id="__codelineno-12-18" name="__codelineno-12-18" href="#__codelineno-12-18"></a>
<a id="__codelineno-12-19" name="__codelineno-12-19" href="#__codelineno-12-19"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_o</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
<a id="__codelineno-12-20" name="__codelineno-12-20" href="#__codelineno-12-20"></a>
<a id="__codelineno-12-21" name="__codelineno-12-21" href="#__codelineno-12-21"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-12-22" name="__codelineno-12-22" href="#__codelineno-12-22"></a>        <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
<a id="__codelineno-12-23" name="__codelineno-12-23" href="#__codelineno-12-23"></a>
<a id="__codelineno-12-24" name="__codelineno-12-24" href="#__codelineno-12-24"></a>        <span class="c1"># 生成Q：每个头独立</span>
<a id="__codelineno-12-25" name="__codelineno-12-25" href="#__codelineno-12-25"></a>        <span class="n">Q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_q</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>
<a id="__codelineno-12-26" name="__codelineno-12-26" href="#__codelineno-12-26"></a>
<a id="__codelineno-12-27" name="__codelineno-12-27" href="#__codelineno-12-27"></a>        <span class="c1"># 生成K,V：按组共享</span>
<a id="__codelineno-12-28" name="__codelineno-12-28" href="#__codelineno-12-28"></a>        <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_k</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_groups</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>
<a id="__codelineno-12-29" name="__codelineno-12-29" href="#__codelineno-12-29"></a>        <span class="n">V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_v</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_groups</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>
<a id="__codelineno-12-30" name="__codelineno-12-30" href="#__codelineno-12-30"></a>
<a id="__codelineno-12-31" name="__codelineno-12-31" href="#__codelineno-12-31"></a>        <span class="c1"># 重复K,V以匹配Q的头数</span>
<a id="__codelineno-12-32" name="__codelineno-12-32" href="#__codelineno-12-32"></a>        <span class="n">K</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">heads_per_group</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-12-33" name="__codelineno-12-33" href="#__codelineno-12-33"></a>        <span class="n">V</span> <span class="o">=</span> <span class="n">V</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">heads_per_group</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-12-34" name="__codelineno-12-34" href="#__codelineno-12-34"></a>
<a id="__codelineno-12-35" name="__codelineno-12-35" href="#__codelineno-12-35"></a>        <span class="c1"># 计算注意力</span>
<a id="__codelineno-12-36" name="__codelineno-12-36" href="#__codelineno-12-36"></a>        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">K</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_k</span><span class="p">)</span>
<a id="__codelineno-12-37" name="__codelineno-12-37" href="#__codelineno-12-37"></a>        <span class="n">attn_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-12-38" name="__codelineno-12-38" href="#__codelineno-12-38"></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attn_weights</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span>
<a id="__codelineno-12-39" name="__codelineno-12-39" href="#__codelineno-12-39"></a>
<a id="__codelineno-12-40" name="__codelineno-12-40" href="#__codelineno-12-40"></a>        <span class="c1"># 合并多头输出</span>
<a id="__codelineno-12-41" name="__codelineno-12-41" href="#__codelineno-12-41"></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
<a id="__codelineno-12-42" name="__codelineno-12-42" href="#__codelineno-12-42"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_o</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</code></pre></div>
<h3 id="3-kv-cache">练习3: KV Cache实现预览<a class="headerlink" href="#3-kv-cache" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="k">class</span><span class="w"> </span><span class="nc">KVCache</span><span class="p">:</span>
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_seq_len</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">d_k</span><span class="p">):</span>
<a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_len</span> <span class="o">=</span> <span class="n">max_seq_len</span>
<a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cache_k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_seq_len</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">d_k</span><span class="p">)</span>
<a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cache_v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_seq_len</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">d_k</span><span class="p">)</span> 
<a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">current_len</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a>
<a id="__codelineno-13-8" name="__codelineno-13-8" href="#__codelineno-13-8"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_k</span><span class="p">,</span> <span class="n">new_v</span><span class="p">):</span>
<a id="__codelineno-13-9" name="__codelineno-13-9" href="#__codelineno-13-9"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;更新缓存并返回完整的K,V&quot;&quot;&quot;</span>
<a id="__codelineno-13-10" name="__codelineno-13-10" href="#__codelineno-13-10"></a>        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">new_k</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-13-11" name="__codelineno-13-11" href="#__codelineno-13-11"></a>
<a id="__codelineno-13-12" name="__codelineno-13-12" href="#__codelineno-13-12"></a>        <span class="c1"># 存储新的K,V</span>
<a id="__codelineno-13-13" name="__codelineno-13-13" href="#__codelineno-13-13"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cache_k</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">current_len</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">current_len</span><span class="o">+</span><span class="n">seq_len</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_k</span>
<a id="__codelineno-13-14" name="__codelineno-13-14" href="#__codelineno-13-14"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">cache_v</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">current_len</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">current_len</span><span class="o">+</span><span class="n">seq_len</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_v</span>
<a id="__codelineno-13-15" name="__codelineno-13-15" href="#__codelineno-13-15"></a>
<a id="__codelineno-13-16" name="__codelineno-13-16" href="#__codelineno-13-16"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">current_len</span> <span class="o">+=</span> <span class="n">seq_len</span>
<a id="__codelineno-13-17" name="__codelineno-13-17" href="#__codelineno-13-17"></a>
<a id="__codelineno-13-18" name="__codelineno-13-18" href="#__codelineno-13-18"></a>        <span class="c1"># 返回到目前为止的完整K,V</span>
<a id="__codelineno-13-19" name="__codelineno-13-19" href="#__codelineno-13-19"></a>        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_k</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">current_len</span><span class="p">],</span> 
<a id="__codelineno-13-20" name="__codelineno-13-20" href="#__codelineno-13-20"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">cache_v</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">current_len</span><span class="p">])</span>
</code></pre></div>
<h2 id="_13">✅ 学习检验<a class="headerlink" href="#_13" title="Permanent link">&para;</a></h2>
<ul>
<li>[ ] 能解释各变体的核心区别</li>
<li>[ ] 理解KV Cache优化的原理</li>
<li>[ ] 完成GQA代码实现</li>
<li>[ ] 能根据场景选择合适的注意力机制</li>
</ul>
<h2 id="_14">🔗 相关链接<a class="headerlink" href="#_14" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="../kv-cache/">下一节：KV Cache技术</a></li>
<li><a href="../">返回：Attention升级概览</a></li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": ["header.autohide", "navigation.tracking", "navigation.top", "search.highlight", "search.share", "search.suggest", "content.code.annotate"], "search": "../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.50899def.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>